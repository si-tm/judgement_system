{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def load_xy(x_path='../../data/npy/x_random_l1_6.npy', y_path='../../data/npy/y_random_l1_6.npy'):\n",
    "\n",
    "    x_data = np.load(x_path)\n",
    "    y_data = np.load(y_path, allow_pickle=True)\n",
    "    # min_val = y_data.min()\n",
    "    # max_val = y_data.max()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "    return x_data, y_data, x_train, x_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "def randomforest_regressor(X, y, X_test, y_test):\n",
    "    regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    regr.fit(X, y)\n",
    "    return regr.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\n",
    "def extratrees_regressor(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=0)\n",
    "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(\n",
    "    X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "def gradientboosting_regressor(X_train, X_test, y_train, y_test):\n",
    "    reg = GradientBoostingRegressor(random_state=0)\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor\n",
    "def stacking_regressor(X_train, X_test, y_train, y_test):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    estimators = [\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42))\n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                            random_state=42)\n",
    "    )\n",
    "    ref = reg.fit(X_train, y_train)\n",
    "    return ref.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor\n",
    "def voting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    r1 = LinearRegression()\n",
    "    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "    r3 = KNeighborsRegressor()\n",
    "    X = x_train\n",
    "    y = y_train\n",
    "    er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])\n",
    "    er = er.fit(X, y)\n",
    "    er.predict(X)\n",
    "    return er.score(x_test, y_test)\n",
    "\n",
    "def histgradientboosting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    est = HistGradientBoostingRegressor().fit(X, y)\n",
    "    return est.score(x_test, y_test)\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "def neural_mse(x, y, x_train, x_test, y_train, y_test):\n",
    "    x_data = x\n",
    "    y_data = y\n",
    "    min_val = y_data.min()\n",
    "    max_val = y_data.max()\n",
    "    y_data = (y_data - min_val)/(max_val - min_val)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "    model = keras.models.load_model('../../script/saved_model/random_l1_6_model')\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    return mse(y_test,test_predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score):\n",
    "\n",
    "    lst = []\n",
    "    lst.append([\"extratrees\" ,extratrees])\n",
    "    lst.append([\"randomforest\", randomforest])\n",
    "    lst.append([\"gradientboosting\", gradientboosting])\n",
    "    lst.append([\"stacking\", stacking])\n",
    "    lst.append([\"voting\", voting])\n",
    "    lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "    lst.append([\"neural network\", neural_mse_score])\n",
    "        \n",
    "    pd.DataFrame(data=lst,columns=['regressor', 'score'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "2023-02-01 17:46:48.901903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x, y, x_train, x_test, y_train, y_test = load_xy()\n",
    "\n",
    "extratrees = extratrees_regressor(x, y)\n",
    "randomforest = randomforest_regressor(X=x_train, y=y_train, X_test=x_test, y_test=y_test) \n",
    "gradientboosting = gradientboosting_regressor(x_train, x_test, y_train, y_test)\n",
    "stacking = stacking_regressor(x_train, x_test, y_train, y_test)\n",
    "voting = voting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "histgradientboosting = histgradientboosting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "neural_mse_score = neural_mse(x, y, x_train, x_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "lst.append([\"extratrees\" ,extratrees])\n",
    "lst.append([\"randomforest\", randomforest])\n",
    "lst.append([\"gradientboosting\", gradientboosting])\n",
    "lst.append([\"stacking\", stacking])\n",
    "lst.append([\"voting\", voting])\n",
    "lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "lst.append([\"neural network\", neural_mse_score])\n",
    "    \n",
    "df = pd.DataFrame(data=lst,columns=['regressor', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfkit as pdf\n",
    "import sqlite3\n",
    "\n",
    "df.to_html('compare_score.html')\n",
    "nazivFajla='compare_score.pdf'\n",
    "pdf.from_file('compare_score.html', nazivFajla)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
