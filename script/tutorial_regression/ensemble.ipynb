{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードよくないかも？\n",
    "x_train, y_trainをしっかり分ける！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def load_xy(x_path='../../data/npy/x_random_l1_6.npy', y_path='../../data/npy/y_random_l1_6.npy'):\n",
    "\n",
    "    x_data = np.load(x_path)\n",
    "    y_data = np.load(y_path, allow_pickle=True)\n",
    "    # min_val = y_data.min()\n",
    "    # max_val = y_data.max()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "    return x_data, y_data, x_train, x_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "# def randomforest_regressor(X, y, X_test, y_test):\n",
    "#     regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "#     regr.fit(X, y)\n",
    "#     return regr.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\n",
    "# def extratrees_regressor(X, y):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, random_state=0)\n",
    "#     reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(\n",
    "#     X_train, y_train)\n",
    "#     return reg.score(X_test, y_test)\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "# def gradientboosting_regressor(X_train, X_test, y_train, y_test):\n",
    "#     reg = GradientBoostingRegressor(random_state=0)\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     return reg.score(X_test, y_test)\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor\n",
    "# def stacking_regressor(X_train, X_test, y_train, y_test):\n",
    "#     X, y = load_diabetes(return_X_y=True)\n",
    "#     estimators = [\n",
    "#         ('lr', RidgeCV()),\n",
    "#         ('svr', LinearSVR(random_state=42))\n",
    "#     ]\n",
    "#     reg = StackingRegressor(\n",
    "#         estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "#                                             random_state=42)\n",
    "#     )\n",
    "#     ref = reg.fit(X_train, y_train)\n",
    "#     return ref.score(X_test, y_test)\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor\n",
    "# def voting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "#     r1 = LinearRegression()\n",
    "#     r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "#     r3 = KNeighborsRegressor()\n",
    "#     X = x_train\n",
    "#     y = y_train\n",
    "#     er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])\n",
    "#     er = er.fit(X, y)\n",
    "#     er.predict(X)\n",
    "#     return er.score(x_test, y_test)\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "# def histgradientboosting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "#     # est = HistGradientBoostingRegressor().fit(X, y)\n",
    "#     est = HistGradientBoostingRegressor().fit(x_train, y_train)\n",
    "#     return est.score(x_test, y_test)\n",
    "\n",
    "# def get_model():\n",
    "#     # Create a simple model.\n",
    "#     inputs = keras.Input(shape=(32,))\n",
    "#     outputs = keras.layers.Dense(1)(inputs)\n",
    "#     model = keras.Model(inputs, outputs)\n",
    "#     model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "#     return model\n",
    "\n",
    "# def neural_mse(x, y, x_train, x_test, y_train, y_test, model_path='../../script/saved_model/random_l1_6_model'):\n",
    "#     x_data = x\n",
    "#     y_data = y\n",
    "#     min_val = y_data.min()\n",
    "#     max_val = y_data.max()\n",
    "#     y_data = (y_data - min_val)/(max_val - min_val)\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "#     model = keras.models.load_model(model_path)\n",
    "#     test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "#     mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#     return mse(y_test,test_predictions).numpy()\n",
    "\n",
    "# def new_neural_mse(x, y, x_train, x_test, y_train, y_test, model_path='../../script/saved_model/random_l1_6_model'):\n",
    "\n",
    "#     model = keras.models.load_model(model_path)\n",
    "#     test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "#     mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#     return mse(y_test,test_predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "def randomforest_regressor(x, y, x_train, x_test, y_train, y_test):\n",
    "    regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    regr.fit(x_train, y_train)\n",
    "    return regr.score(x_test, y_test)\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\n",
    "def extratrees_regressor(x, y, x_train, x_test, y_train, y_test):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     X, y, random_state=0)\n",
    "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(\n",
    "    x_train, y_train)\n",
    "    return reg.score(x_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "def gradientboosting_regressor(X_train, X_test, y_train, y_test):\n",
    "    reg = GradientBoostingRegressor(random_state=0)\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor\n",
    "def stacking_regressor(X_train, X_test, y_train, y_test):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    estimators = [\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42))\n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                            random_state=42)\n",
    "    )\n",
    "    ref = reg.fit(X_train, y_train)\n",
    "    return ref.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor\n",
    "def voting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    r1 = LinearRegression()\n",
    "    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "    r3 = KNeighborsRegressor()\n",
    "    X = x_train\n",
    "    y = y_train\n",
    "    er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])\n",
    "    er = er.fit(X, y)\n",
    "    er.predict(X)\n",
    "    return er.score(x_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "def histgradientboosting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    # est = HistGradientBoostingRegressor().fit(X, y)\n",
    "    est = HistGradientBoostingRegressor().fit(x_train, y_train)\n",
    "    return est.score(x_test, y_test)\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "def neural_mse(x, y, x_train, x_test, y_train, y_test, model_path='../../script/saved_model/random_l1_6_model'):\n",
    "    x_data = x\n",
    "    y_data = y\n",
    "    min_val = y_data.min()\n",
    "    max_val = y_data.max()\n",
    "    y_data = (y_data - min_val)/(max_val - min_val)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    return mse(y_test,test_predictions).numpy()\n",
    "\n",
    "def new_neural_mse(x, y, x_train, x_test, y_train, y_test, model_path='../../script/saved_model/random_l1_6_model'):\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    return mse(y_test,test_predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score):\n",
    "\n",
    "    lst = []\n",
    "    lst.append([\"extratrees\" ,extratrees])\n",
    "    lst.append([\"randomforest\", randomforest])\n",
    "    lst.append([\"gradientboosting\", gradientboosting])\n",
    "    lst.append([\"stacking\", stacking])\n",
    "    lst.append([\"voting\", voting])\n",
    "    lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "    lst.append([\"neural network\", neural_mse_score])\n",
    "        \n",
    "    pd.DataFrame(data=lst,columns=['regressor', 'score'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 602us/step\n"
     ]
    }
   ],
   "source": [
    "x, y, x_train, x_test, y_train, y_test = load_xy()\n",
    "\n",
    "extratrees = extratrees_regressor(x, y)\n",
    "randomforest = randomforest_regressor(X=x_train, y=y_train, X_test=x_test, y_test=y_test) \n",
    "gradientboosting = gradientboosting_regressor(x_train, x_test, y_train, y_test)\n",
    "stacking = stacking_regressor(x_train, x_test, y_train, y_test)\n",
    "voting = voting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "histgradientboosting = histgradientboosting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "neural_mse_score = neural_mse(x, y, x_train, x_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              regressor     score\n",
      "0            extratrees -1.100624\n",
      "1          randomforest -0.021517\n",
      "2      gradientboosting -0.089980\n",
      "3              stacking -0.366923\n",
      "4                voting -0.133218\n",
      "5  histgradientboosting -0.219124\n",
      "6        neural network  0.010725\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "lst.append([\"extratrees\" ,extratrees])\n",
    "lst.append([\"randomforest\", randomforest])\n",
    "lst.append([\"gradientboosting\", gradientboosting])\n",
    "lst.append([\"stacking\", stacking])\n",
    "lst.append([\"voting\", voting])\n",
    "lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "lst.append([\"neural network\", neural_mse_score])\n",
    "    \n",
    "df = pd.DataFrame(data=lst,columns=['regressor', 'score'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdfkit\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpdf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlite3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[39m.\u001b[39mto_html(\u001b[39m'\u001b[39m\u001b[39mcompare_score.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfkit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfkit as pdf\n",
    "import sqlite3\n",
    "\n",
    "df.to_html('compare_score.html')\n",
    "nazivFajla='compare_score.pdf'\n",
    "pdf.from_file('compare_score.html', nazivFajla)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result():\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "    res = linregress(test_predictions, y_test)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, test_predictions)\n",
    "    # plt.xlabel('True Values [mc]')\n",
    "    # plt.ylabel('Predictions [mc]')\n",
    "    plt.xlabel('True Values of volume ')\n",
    "    plt.ylabel('Predictions of volume')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([-0.5,1])\n",
    "    plt.ylim([-0.5,1])\n",
    "    _ = plt.plot([-0.5, 1], [-0.5, 1])\n",
    "\n",
    "    plt.plot([-0.5, 1], res.intercept + res.slope*np.array([-1, 1]), 'r', label='fitted line')\n",
    "\n",
    "    # normalizer 学習前"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1\n",
    "import os\n",
    "x_l1_mean_fullPath = os.path.abspath('../../data/npy/x_random_l1_6_mean.npy')\n",
    "x_l1_rb_fullPath = os.path.abspath('../../data/npy/x_random_l1_6_rb.npy')\n",
    "x_l1_dv_fullPath = os.path.abspath('../../data/npy/x_random_l1_6_dv.npy')\n",
    "x_l1_mean_path = tf.keras.utils.get_file('x_random_l1_6_mean.npy', 'file://'+x_l1_mean_fullPath)\n",
    "x_l1_rb_path = tf.keras.utils.get_file('x_random_l1_6_mean.npy', 'file://'+x_l1_rb_fullPath)\n",
    "x_l1_dv_path = tf.keras.utils.get_file('x_random_l1_6_mean.npy', 'file://'+x_l1_dv_fullPath)\n",
    "\n",
    "y_l1_mean_fullPath = os.path.abspath('../../data/npy/y_random_l1_6_mean.npy')\n",
    "y_l1_rb_fullPath = os.path.abspath('../../data/npy/y_random_l1_6_rb.npy')\n",
    "y_l1_dv_fullPath = os.path.abspath('../../data/npy/y_random_l1_6_dv.npy')\n",
    "y_l1_mean_path = tf.keras.utils.get_file('y_random_l1_6_mean.npy', 'file://'+y_l1_mean_fullPath)\n",
    "y_l1_rb_path = tf.keras.utils.get_file('y_random_l1_6_rb.npy', 'file://'+y_l1_rb_fullPath)\n",
    "y_l1_dv_path = tf.keras.utils.get_file('y_random_l1_6_dv.npy', 'file://'+y_l1_dv_fullPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_comparison_with_mse(x_path=x_l1_mean_path, y_path=y_l1_mean_path, model_path='../../saved_model/l1_ave_230530'):\n",
    "\n",
    "    x, y, x_train, x_test, y_train, y_test = load_xy(x_path, y_path)\n",
    "\n",
    "    extratrees = extratrees_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "    randomforest = randomforest_regressor(x, y, x_train, x_test, y_train, y_test) \n",
    "    gradientboosting = gradientboosting_regressor(x_train, x_test, y_train, y_test)\n",
    "    stacking = stacking_regressor(x_train, x_test, y_train, y_test)\n",
    "    voting = voting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "    histgradientboosting = histgradientboosting_regressor(x, y, x_train, x_test, y_train, y_test)\n",
    "    neural_mse_score = new_neural_mse(x, y, x_train, x_test, y_train, y_test, model_path)\n",
    "    data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score)\n",
    "    lst = []\n",
    "    lst.append([\"extratrees\" ,extratrees])\n",
    "    lst.append([\"randomforest\", randomforest])\n",
    "    lst.append([\"gradientboosting\", gradientboosting])\n",
    "    lst.append([\"stacking\", stacking])\n",
    "    lst.append([\"voting\", voting])\n",
    "    lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "    lst.append([\"neural network\", neural_mse_score])\n",
    "        \n",
    "    df = pd.DataFrame(data=lst,columns=['regressor', 'score'])\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 607us/step\n",
      "              regressor     score\n",
      "0            extratrees -1.127213\n",
      "1          randomforest -0.009465\n",
      "2      gradientboosting -0.062178\n",
      "3              stacking -0.325583\n",
      "4                voting -0.094437\n",
      "5  histgradientboosting -0.127424\n",
      "6        neural network  0.163850\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l1_mean_path, y_path=y_l1_mean_path, model_path='../../saved_model/l1_ave_230530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 702us/step\n",
      "              regressor     score\n",
      "0            extratrees  0.162193\n",
      "1          randomforest  0.142085\n",
      "2      gradientboosting  0.861401\n",
      "3              stacking  1.000000\n",
      "4                voting  0.810717\n",
      "5  histgradientboosting  0.917971\n",
      "6        neural network  0.021884\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l1_dv_path, y_path=y_l1_dv_path, model_path='../../saved_model/l1_dev_0605')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "x_l2_mean_fullPath = os.path.abspath('../../data/npy/x_random_l2_6_mean.npy')\n",
    "x_l2_rb_fullPath = os.path.abspath('../../data/npy/x_random_l2_6_rb.npy')\n",
    "x_l2_dv_fullPath = os.path.abspath('../../data/npy/x_random_l2_6_dv.npy')\n",
    "x_l2_mean_path = tf.keras.utils.get_file('x_random_l2_6_mean.npy', 'file://'+x_l2_mean_fullPath)\n",
    "x_l2_rb_path = tf.keras.utils.get_file('x_random_l2_6_mean.npy', 'file://'+x_l2_rb_fullPath)\n",
    "x_l2_dv_path = tf.keras.utils.get_file('x_random_l2_6_mean.npy', 'file://'+x_l2_dv_fullPath)\n",
    "\n",
    "y_l2_mean_fullPath = os.path.abspath('../../data/npy/y_random_l2_6_mean.npy')\n",
    "y_l2_rb_fullPath = os.path.abspath('../../data/npy/y_random_l2_6_rb.npy')\n",
    "y_l2_dv_fullPath = os.path.abspath('../../data/npy/y_random_l2_6_dv.npy')\n",
    "y_l2_mean_path = tf.keras.utils.get_file('y_random_l2_6_mean.npy', 'file://'+y_l2_mean_fullPath)\n",
    "y_l2_rb_path = tf.keras.utils.get_file('y_random_l2_6_mean.npy', 'file://'+y_l2_rb_fullPath)\n",
    "y_l2_dv_path = tf.keras.utils.get_file('y_random_l2_6_mean.npy', 'file://'+y_l2_dv_fullPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 720us/step\n",
      "              regressor     score\n",
      "0            extratrees -0.617528\n",
      "1          randomforest  0.002703\n",
      "2      gradientboosting -0.036118\n",
      "3              stacking -0.314276\n",
      "4                voting -0.100350\n",
      "5  histgradientboosting -0.094499\n",
      "6        neural network  0.129770\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l2_mean_path, y_path=y_l2_mean_path, model_path='../../saved_model/l2_ave_230613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/hyakuzukamaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 670us/step\n",
      "              regressor      score\n",
      "0            extratrees  -0.881199\n",
      "1          randomforest  -0.004157\n",
      "2      gradientboosting  -0.033266\n",
      "3              stacking  -0.329224\n",
      "4                voting  -0.127970\n",
      "5  histgradientboosting  -0.078021\n",
      "6        neural network  30.743013\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l2_dv_path, y_path=y_l2_dv_path, model_path='../../saved_model/l2_dev_230613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l3\n",
    "x_l3_mean_fullPath = os.path.abspath('../../data/npy/x_random_l3_6_mean.npy')\n",
    "x_l3_rb_fullPath = os.path.abspath('../../data/npy/x_random_l3_6_rb.npy')\n",
    "x_l3_dv_fullPath = os.path.abspath('../../data/npy/x_random_l3_6_dv.npy')\n",
    "x_l3_mean_path = tf.keras.utils.get_file('x_random_l3_6_mean.npy', 'file://'+x_l3_mean_fullPath)\n",
    "x_l3_rb_path = tf.keras.utils.get_file('x_random_l3_6_mean.npy', 'file://'+x_l3_rb_fullPath)\n",
    "x_l3_dv_path = tf.keras.utils.get_file('x_random_l3_6_mean.npy', 'file://'+x_l3_dv_fullPath)\n",
    "\n",
    "y_l3_mean_fullPath = os.path.abspath('../../data/npy/y_random_l3_6_mean.npy')\n",
    "y_l3_rb_fullPath = os.path.abspath('../../data/npy/y_random_l3_6_rb.npy')\n",
    "y_l3_dv_fullPath = os.path.abspath('../../data/npy/y_random_l3_6_dv.npy')\n",
    "y_l3_mean_path = tf.keras.utils.get_file('y_random_l3_6_mean.npy', 'file://'+y_l3_mean_fullPath)\n",
    "y_l3_rb_path = tf.keras.utils.get_file('y_random_l3_6_rb.npy', 'file://'+y_l3_rb_fullPath)\n",
    "y_l3_dv_path = tf.keras.utils.get_file('y_random_l3_6_dv.npy', 'file://'+y_l3_dv_fullPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 822us/step\n",
      "              regressor      score\n",
      "0            extratrees  -0.431777\n",
      "1          randomforest  -0.016181\n",
      "2      gradientboosting  -0.032032\n",
      "3              stacking  -0.384827\n",
      "4                voting  -0.468185\n",
      "5  histgradientboosting  -0.012914\n",
      "6        neural network  65.650963\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l3_mean_path, y_path=y_l3_mean_path, model_path='../../saved_model/l3_ave_230613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 882us/step\n",
      "              regressor     score\n",
      "0            extratrees -0.501109\n",
      "1          randomforest -0.029870\n",
      "2      gradientboosting -0.044938\n",
      "3              stacking -0.210699\n",
      "4                voting -0.226842\n",
      "5  histgradientboosting -0.031036\n",
      "6        neural network  3.641430\n"
     ]
    }
   ],
   "source": [
    "result_comparison_with_mse(x_path=x_l3_dv_path, y_path=y_l3_dv_path, model_path='../../saved_model/l3_dev_230613')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
