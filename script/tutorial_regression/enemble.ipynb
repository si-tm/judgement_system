{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:27:23.303253: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "import loading_data as ld\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "def randomforest_regressor(X, y, X_test, y_test):\n",
    "    regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    regr.fit(X, y)\n",
    "    return regr.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\n",
    "def extratrees_regressor(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=0)\n",
    "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(\n",
    "    X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "def gradientboosting_regressor(X_train, X_test, y_train, y_test):\n",
    "    reg = GradientBoostingRegressor(random_state=0)\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor\n",
    "def stacking_regressor(X_train, X_test, y_train, y_test):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    estimators = [\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42))\n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                            random_state=42)\n",
    "    )\n",
    "    ref = reg.fit(X_train, y_train)\n",
    "    return ref.score(X_test, y_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor\n",
    "def voting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    r1 = LinearRegression()\n",
    "    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "    r3 = KNeighborsRegressor()\n",
    "    X = x_train\n",
    "    y = y_train\n",
    "    er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])\n",
    "    er = er.fit(X, y)\n",
    "    er.predict(X)\n",
    "    return er.score(x_test, y_test)\n",
    "\n",
    "def histgradientboosting_regressor(X, y, x_train, x_test, y_train, y_test):\n",
    "    est = HistGradientBoostingRegressor().fit(X, y)\n",
    "    return est.score(x_test, y_test)\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "def neural_mse(x, y, x_train, x_test, y_train, y_test):\n",
    "    x_data = x\n",
    "    y_data = y\n",
    "    min_val = y_data.min()\n",
    "    max_val = y_data.max()\n",
    "    y_data = (y_data - min_val)/(max_val - min_val)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "    model = keras.models.load_model('../saved_model/random_l1_6_model')\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    return mse(y_test,test_predictions).numpy()\n",
    "\n",
    "def data_print(extratrees, randomforest, gradientboosting, stacking, voting, histgradientboosting, neural_mse_score):\n",
    "\n",
    "    lst = []\n",
    "    lst.append([\"extratrees\" ,extratrees])\n",
    "    lst.append([\"randomforest\", randomforest])\n",
    "    lst.append([\"gradientboosting\", gradientboosting])\n",
    "    lst.append([\"stacking\", stacking])\n",
    "    lst.append([\"voting\", voting])\n",
    "    lst.append([\"histgradientboosting\", histgradientboosting])\n",
    "    lst.append([\"neural network\", neural_mse_score])\n",
    "        \n",
    "    df = pd.DataFrame(data=lst,columns=['regressor', 'score'])\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histgradientboosting_regressor_(X, y, x_train, x_test, y_train, y_test):\n",
    "    est = HistGradientBoostingRegressor().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (589990830.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def plot_result()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def plot_result()\n",
    "    test_predictions = model.predict(x_test).flatten()\n",
    "    res = linregress(test_predictions, y_test)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, test_predictions)\n",
    "    # plt.xlabel('True Values [mc]')\n",
    "    # plt.ylabel('Predictions [mc]')\n",
    "    plt.xlabel('True Values of volume ')\n",
    "    plt.ylabel('Predictions of volume')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([-0.5,1])\n",
    "    plt.ylim([-0.5,1])\n",
    "    _ = plt.plot([-0.5, 1], [-0.5, 1])\n",
    "\n",
    "    plt.plot([-0.5, 1], res.intercept + res.slope*np.array([-1, 1]), 'r', label='fitted line')\n",
    "\n",
    "    # normalizer 学習前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
