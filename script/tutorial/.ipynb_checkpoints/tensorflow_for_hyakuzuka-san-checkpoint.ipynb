{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train data and test data as dataset\n",
    "- データセットとして使用するデータを取得する。\n",
    "- trainデータとtestデータに分割する。（例えば80%をtrainデータに、20%をtestデータに、など。）\n",
    "- 書き方はデータセットとして使用するデータの type による。もし、numpy の形で持っているならhttps://www.tensorflow.org/tutorials/load_data/numpy?hl=ja が参考になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_fullPath = os.path.abspath('x.npy')\n",
    "x_path = tf.keras.utils.get_file('x.npy', 'file://'+x_fullPath)\n",
    "x_data = np.load(myarray_path)\n",
    "\n",
    "y_fullPath = os.path.abspath('x.npy')\n",
    "y_path = tf.keras.utils.get_file('y.npy', 'file://'+y_fullPath)\n",
    "y_data = np.load(mc_path)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(myarray_data, mc_data, test_size=0.2)\n",
    "\n",
    "print(len(x_train), 'train examples')\n",
    "print(len(x_test), 'test examples')\n",
    "print(len(y_train), 'train examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set my model\n",
    "- input_shape は入力データのサイズ。\n",
    "- モデルの定義方法は調べればたくさん出てきますが、例えばここ： https://sinyblog.com/deaplearning/keras_how_to/ \n",
    "- 最後の層の出力は、期待する出力データのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(15, activation='relu', input_shape=[...], use_bias=True),\n",
    "        layers.Dense(...), # こんな感じで中間層を増やしたりできます\n",
    "        layers.Dense(..., activation=lambda x: tf.math.abs(x))\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam() # optimizers も Adam 以外に色々種類があります。調べてみてください！\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse']) # loss 関数に何を採用するかはどんな問題を解きたいのかによります。\n",
    "                                        #ここでは MSE を採用していますが、他にも色々な選択肢があります。調べてみてください！\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_batch = x_train[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# エポックが終わるごとにドットを一つ出力することで進捗を表示\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "EPOCHS = 400 # epoch 数も考慮しよう\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "    callbacks=[PrintDot()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [mc]')\n",
    "    plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n",
    "    plt.ylim([0,30])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$mc^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "    plt.ylim([0,400])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test).flatten()\n",
    "res = linregress(test_predictions, y_test)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values [mc]')\n",
    "plt.ylabel('Predictions [mc]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([-1,100])\n",
    "plt.ylim([-1,100])\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "\n",
    "plt.plot([-1, 100], res.intercept + res.slope*np.array([-1, 100]), 'r', label='fitted line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# トレーニングした model をどこかで使用したいなら以下のようにモデルを保存する\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
