{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train data and test data as dataset\n",
    "- データセットとして使用するデータを取得する。\n",
    "- trainデータとtestデータに分割する。（例えば80%をtrainデータに、20%をtestデータに、など。）\n",
    "- 書き方はデータセットとして使用するデータの type による。もし、numpy の形で持っているならhttps://www.tensorflow.org/tutorials/load_data/numpy?hl=ja が参考になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 1, 28560)\n",
      "(24, 1, 28560)\n",
      "(94,)\n",
      "(24,)\n",
      "94 train examples\n",
      "24 test examples\n",
      "94 train examples\n"
     ]
    }
   ],
   "source": [
    "# x_fullPath = os.path.abspath('x.npy')\n",
    "x_fullPath = os.path.abspath('../../data/npy/x1.npy')\n",
    "x_path = tf.keras.utils.get_file('x1.npy', 'file://'+x_fullPath)\n",
    "# x_fullPath = os.path.abspath('../../data/npy/x2.npy')\n",
    "# x_path = tf.keras.utils.get_file('x2.npy', 'file://'+x_fullPath)\n",
    "# x_data = np.load(myarray_path)\n",
    "x_data = np.load(x_path)\n",
    "\n",
    "y_fullPath = os.path.abspath('../../data/npy/y.npy')\n",
    "y_path = tf.keras.utils.get_file('y.npy', 'file://'+y_fullPath)\n",
    "y_data = np.load(y_path)\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(myarray_data, mc_data, test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "# expected shape=(None, 118, 28560)\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "# x_test = np.reshape(x_test, (x_test.shape[0], 1,x_test.shape[1]))\n",
    "x_train = np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(len(x_train), 'train examples')\n",
    "print(len(x_test), 'test examples')\n",
    "print(len(y_train), 'train examples')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set my model\n",
    "- input_shape は入力データのサイズ。\n",
    "- モデルの定義方法は調べればたくさん出てきますが、例えばここ： https://sinyblog.com/deaplearning/keras_how_to/ \n",
    "- 最後の層の出力は、期待する出力データのサイズ\n",
    "- [model](https://github.com/si-tm/docs-l10n/blob/master/site/ja/tutorials/quickstart/beginner.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(94, 28560)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # units=128 : 出力空間の次元数\n",
    "    tf.keras.layers.Dropout(0.2), # 入力にドロップアウトを適用する rate=0.2 : 入力ユニットをドロップする割合\n",
    "    tf.keras.layers.Dense(1) \n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam() # optimizers も Adam 以外に色々種類があります。調べてみてください！\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse']) # loss 関数に何を採用するかはどんな問題を解きたいのかによります。\n",
    "                                        #ここでは MSE を採用していますが、他にも色々な選択肢があります。調べてみてください！\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 2684640)           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               343634048 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343,634,177\n",
      "Trainable params: 343,634,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 28560)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 94, 28560), found shape=(None, 1, 28560)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル10 を /Users/maya/OneDrive - お茶の水女子大学/lab/judgement_system/script/tutorial/tutorial1.ipynb\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial1.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m example_batch \u001b[39m=\u001b[39m x_train[:\u001b[39m10\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial1.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(example_batch\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial1.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m example_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(example_batch)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/gz/q2fd6h093nl1_7qk2mgc25xm0000gn/T/__autograph_generated_file867g6m0n.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 94, 28560), found shape=(None, 1, 28560)\n"
     ]
    }
   ],
   "source": [
    "example_batch = x_train[:10]\n",
    "print(example_batch.shape)\n",
    "example_result = model.predict(example_batch)\n",
    "# example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# エポックが終わるごとにドットを一つ出力することで進捗を表示\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# EPOCHS = 400 # epoch 数も考慮しよう\n",
    "EPOCHS = 10 # epoch 数も考慮しよう\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "    callbacks=[PrintDot()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [mc]')\n",
    "    plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n",
    "    plt.ylim([0,30])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$mc^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "    plt.ylim([0,400])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test).flatten()\n",
    "res = linregress(test_predictions, y_test)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values [mc]')\n",
    "plt.ylabel('Predictions [mc]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([-1,100])\n",
    "plt.ylim([-1,100])\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "\n",
    "plt.plot([-1, 100], res.intercept + res.slope*np.array([-1, 100]), 'r', label='fitted line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# トレーニングした model をどこかで使用したいなら以下のようにモデルを保存する\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
