{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train data and test data as dataset\n",
    "- データセットとして使用するデータを取得する。\n",
    "- trainデータとtestデータに分割する。（例えば80%をtrainデータに、20%をtestデータに、など。）\n",
    "- 書き方はデータセットとして使用するデータの type による。もし、numpy の形で持っているならhttps://www.tensorflow.org/tutorials/load_data/numpy?hl=ja が参考になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 94, 28560)\n",
      "(1, 24, 28560)\n",
      "(94,)\n",
      "(24,)\n",
      "1 train examples\n",
      "1 test examples\n",
      "94 train examples\n"
     ]
    }
   ],
   "source": [
    "# x_fullPath = os.path.abspath('x.npy')\n",
    "x_fullPath = os.path.abspath('../../data/npy/x1_l1_1.npy')\n",
    "x_path = tf.keras.utils.get_file('x1.npy', 'file://'+x_fullPath)\n",
    "# x_fullPath = os.path.abspath('../../data/npy/x2.npy')\n",
    "# x_path = tf.keras.utils.get_file('x2.npy', 'file://'+x_fullPath)\n",
    "# x_data = np.load(myarray_path)\n",
    "x_data = np.load(x_path)\n",
    "\n",
    "y_fullPath = os.path.abspath('../../data/npy/y_l1_1.npy')\n",
    "y_path = tf.keras.utils.get_file('y.npy', 'file://'+y_fullPath)\n",
    "y_data = np.load(y_path)\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(myarray_data, mc_data, test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "# expected shape=(None, 118, 28560)\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "# x_test = np.reshape(x_test, (x_test.shape[0], 1,x_test.shape[1]))\n",
    "x_train = np.reshape(x_train, (, x_train.shape[0], x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(len(x_train), 'train examples')\n",
    "print(len(x_test), 'test examples')\n",
    "print(len(y_train), 'train examples')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set my model\n",
    "- input_shape は入力データのサイズ。\n",
    "- モデルの定義方法は調べればたくさん出てきますが、例えばここ： https://sinyblog.com/deaplearning/keras_how_to/ \n",
    "- 最後の層の出力は、期待する出力データのサイズ\n",
    "- [model](https://github.com/si-tm/docs-l10n/blob/master/site/ja/tutorials/quickstart/beginner.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(94, 28560)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # units=128 : 出力空間の次元数\n",
    "    tf.keras.layers.Dropout(0.2), # 入力にドロップアウトを適用する rate=0.2 : 入力ユニットをドロップする割合\n",
    "    tf.keras.layers.Dense(1) \n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam() # optimizers も Adam 以外に色々種類があります。調べてみてください！\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse']) # loss 関数に何を採用するかはどんな問題を解きたいのかによります。\n",
    "                                        #ここでは MSE を採用していますが、他にも色々な選択肢があります。調べてみてください！\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 13:22:47.347089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 2684640)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               343634048 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343,634,177\n",
      "Trainable params: 343,634,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 94, 28560)\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "example_batch = x_train[:10]\n",
    "print(example_batch.shape)\n",
    "example_result = model.predict(example_batch)\n",
    "# example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02428719]]\n"
     ]
    }
   ],
   "source": [
    "print(example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル12 を /Users/maya/OneDrive - お茶の水女子大学/lab/judgement_system/script/tutorial/tutorial2.ipynb\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# EPOCHS = 400 # epoch 数も考慮しよう\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m# epoch 数も考慮しよう\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x_train, y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_split \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[PrintDot()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maya/OneDrive%20-%20%E3%81%8A%E8%8C%B6%E3%81%AE%E6%B0%B4%E5%A5%B3%E5%AD%90%E5%A4%A7%E5%AD%A6/lab/judgement_system/script/tutorial/tutorial2.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/data_adapter.py:1498\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m   1495\u001b[0m split_at \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(math\u001b[39m.\u001b[39mfloor(batch_dim \u001b[39m*\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m validation_split)))\n\u001b[1;32m   1497\u001b[0m \u001b[39mif\u001b[39;00m split_at \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m split_at \u001b[39m==\u001b[39m batch_dim:\n\u001b[0;32m-> 1498\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1499\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mTraining data contains \u001b[39m\u001b[39m{batch_dim}\u001b[39;00m\u001b[39m samples, which is not sufficient \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1500\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto split it into a validation and training set as specified by \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1501\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`validation_split=\u001b[39m\u001b[39m{validation_split}\u001b[39;00m\u001b[39m`. Either provide more data, or a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mdifferent value for the `validation_split` argument.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m           batch_dim\u001b[39m=\u001b[39mbatch_dim, validation_split\u001b[39m=\u001b[39mvalidation_split))\n\u001b[1;32m   1505\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split\u001b[39m(t, start, end):\n\u001b[1;32m   1506\u001b[0m   \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "# エポックが終わるごとにドットを一つ出力することで進捗を表示\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# EPOCHS = 400 # epoch 数も考慮しよう\n",
    "EPOCHS = 10 # epoch 数も考慮しよう\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "    callbacks=[PrintDot()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [mc]')\n",
    "    plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n",
    "    plt.ylim([0,30])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$mc^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "    plt.ylim([0,400])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test).flatten()\n",
    "res = linregress(test_predictions, y_test)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values [mc]')\n",
    "plt.ylabel('Predictions [mc]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([-1,100])\n",
    "plt.ylim([-1,100])\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "\n",
    "plt.plot([-1, 100], res.intercept + res.slope*np.array([-1, 100]), 'r', label='fitted line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# トレーニングした model をどこかで使用したいなら以下のようにモデルを保存する\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
